{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"Lab_3.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_iPQBHO3_VYw","executionInfo":{"status":"ok","timestamp":1633642640683,"user_tz":300,"elapsed":425,"user":{"displayName":"Ting-Yu Dai","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17719512292427902131"}},"outputId":"a21ae568-66bf-4f6d-a6df-615d0798a555"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","dir = '/content/drive/MyDrive/Courses/2021fall/Spoken Language Technologies/Lab3/data/'\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1VFL7YjCvyO2","executionInfo":{"status":"ok","timestamp":1633648863093,"user_tz":300,"elapsed":293,"user":{"displayName":"Ting-Yu Dai","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17719512292427902131"}},"outputId":"6ba148c1-033d-41af-dd38-2c6e998af1f0"},"source":["import librosa\n","import math\n","import numpy as np\n","import scipy.signal\n","from scipy.special import logsumexp\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","class MyNet(nn.Module):\n","    def __init__(self):\n","        super(MyNet, self).__init__()\n","        self.conv1 = nn.Conv2d(1, 32, 5, padding=2)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.conv2 = nn.Conv2d(32, 64, 5, padding=2)\n","        self.conv3 = nn.Conv2d(64, 64, 3, padding=1)\n","        self.conv4 = nn.Conv2d(64, 128, (1, 5))\n","        self.fc1 = nn.Linear(128, 128)\n","        self.fc2 = nn.Linear(128, 128)\n","        self.fc3 = nn.Linear(128, 48)\n","        self.sm = nn.LogSoftmax(dim=1)\n","\n","    def forward(self, x):\n","        x = x.unsqueeze(1)\n","        x = self.pool(F.relu(self.conv1(x)))\n","        x = self.pool(F.relu(self.conv2(x)))\n","        x = self.pool(F.relu(self.conv3(x)))\n","        x = F.relu(self.conv4(x))\n","        x = x.view(-1, 128)\n","        x = F.relu(self.fc1(x))\n","        x = F.relu(self.fc2(x))\n","        x = self.fc3(x)\n","        x = self.sm(x)\n","        return x\n","    \n","def load_audio_to_melspec_tensor(wavpath, sample_rate=16000):\n","    window_size = .025\n","    window_stride = 0.01\n","    n_dft = 512\n","    win_length = int(sample_rate * window_size)\n","    hop_length = int(sample_rate * window_stride)\n","    y, sr = librosa.load(wavpath, sr=sample_rate)\n","    y = y - y.mean()\n","    y = np.append(y[0],y[1:]-.97*y[:-1])\n","    # compute mel spectrogram\n","    stft = librosa.stft(y, n_fft=n_dft, hop_length=hop_length,\n","        win_length=win_length, window=scipy.signal.hamming)\n","    spec = np.abs(stft)**2\n","    mel_basis = librosa.filters.mel(sample_rate, n_dft, n_mels=40, fmin=20)\n","    melspec = np.dot(mel_basis, spec)\n","    logspec = librosa.power_to_db(melspec, ref=np.max)\n","    logspec = np.transpose(logspec)\n","    logspec_tensor = torch.tensor(logspec)\n","    return logspec_tensor\n","\n","def compute_phone_likelihoods(model, logspec):\n","    likelihood_list = []\n","    with torch.no_grad():\n","        for j in range(6, logspec.size(0) - 5):\n","            inp = logspec[j-5:j+6,:].unsqueeze(0)\n","            output = model(inp) # output will be log probabilities over classes\n","            output = output - math.log(1. / 48) # subtract the logprob of the class priors (assumed to be uniform)\n","            likelihood_list.append(output[0])\n","    likelihoods = torch.transpose(torch.stack(likelihood_list, dim=1), 0, 1).numpy()\n","    return likelihoods\n","\n","class MyHMM:\n","    def __init__(self, state_labels, initial_state_distribution, transition_matrix, eps=1e-200):\n","        self.eps = eps\n","        self.pi = np.log(initial_state_distribution + eps)\n","        self.A = np.log(transition_matrix + eps) #A_{ji} is prob of transitioning from state j to state i\n","        self.labels = state_labels # a list where self.labels[j] is the index of the phone label belonging to the jth state\n","        print(self.labels)\n","        self.N_states = len(self.labels)\n","        \n","    def forward(self, state_likelihoods):\n","        # state_likelihoods.shape is assumed to be (N_timesteps, 48)\n","        alpha = np.zeros((state_likelihoods.shape[0], self.N_states))\n","\n","        # Initialization\n","        alpha[0] = state_likelihoods[0, self.labels] + self.pi[0]\n","\n","        # Induction\n","        for i in range(1, state_likelihoods.shape[0]):\n","            alpha[i] = logsumexp(alpha[i - 1, :, None] + self.A, axis = 0) + state_likelihoods[i, self.labels]\n","\n","        # Termination\n","        return alpha[state_likelihoods.shape[0] - 1][self.N_states - 1]\n","    \n","    def viterbi(self, state_likelihoods):\n","        # state_likelihoods.shape is assumed to be (N_timesteps, 48)\n","        delta = np.zeros((state_likelihoods.shape[0], self.N_states))\n","        psi = np.zeros((state_likelihoods.shape[0], self.N_states)).astype(np.int32)\n","\n","        # Initialization\n","        delta[0] = state_likelihoods[0, self.labels] + self.pi[0] \n","\n","        # Induction\n","        for i in range(1, state_likelihoods.shape[0]):\n","            delta[i] = np.max(delta[i - 1, :, None] + self.A, axis = 0) + state_likelihoods[i, self.labels]\n","            psi[i] = np.argmax(delta[i - 1, :, None] + self.A, axis = 0)\n","\n","        # Backtrace\n","        S_opt = np.zeros(state_likelihoods.shape[0]).astype(np.int32)\n","        S_opt[state_likelihoods.shape[0] - 1] = psi[state_likelihoods.shape[0] - 1][self.N_states - 1]\n","        for n in range(state_likelihoods.shape[0] - 2, -1, -1):\n","            S_opt[n] = psi[n, int(S_opt[n+1])]\n","\n","        return delta[state_likelihoods.shape[0]-1, self.N_states-1], S_opt\n","    \n","    def viterbi_transition_update(self, state_likelihoods):\n","        # state_likelihoods.shape is assumed to be (N_timesteps, 48)\n","        # using Viterbi Decoding function\n","        delta, S_opt = self.viterbi(state_likelihoods)\n","        \n","        new_A = np.zeros_like(self.A, dtype=int)\n","        # updating A function\n","        \n","        for t in range(0, state_likelihoods.shape[0] - 1):\n","            new_A[S_opt[t]][S_opt[t + 1]] += 1\n","        new_A = new_A / np.sum(new_A, axis=1)[:, None]\n","        \n","        self.A = np.log(new_A + self.eps)\n","        return\n","\n","model = MyNet()\n","model.load_state_dict(torch.load(dir + 'lab3_AM.pt'))\n","\n","lab3_data = np.load(dir + 'lab3_phone_labels.npz')\n","phone_labels = list(lab3_data['phone_labels'])\n","def phones2indices(phones):\n","    return [phone_labels.index(p) for p in phones]\n","\n","fee_HMM = MyHMM(phones2indices(['sil', 'f', 'iy', 'sil']), np.array([0.5, 0.5, 0, 0]), np.array([[.9,.1,0,0],[0,.9,.1,0],[0,0,.9,.1],[0,0,0,1]]))\n","pea_HMM = MyHMM(phones2indices(['sil', 'p', 'iy', 'sil']), np.array([0.5, 0.5, 0, 0]), np.array([[.9,.1,0,0],[0,.9,.1,0],[0,0,.9,.1],[0,0,0,1]]))\n","rock_HMM = MyHMM(phones2indices(['sil', 'r', 'aa', 'cl', 'k', 'sil']), np.array([0.5,0.5,0,0,0,0]), np.array([[.9,.1,0,0,0,0],[0,.9,.1,0,0,0],[0,0,.9,.1,0,0],[0,0,0,.9,.1,0],[0,0,0,0,.9,.1],[0,0,0,0,0,1]]))\n","burt_HMM = MyHMM(phones2indices(['sil', 'b', 'er', 'cl', 't', 'sil']), np.array([0.5,0.5,0,0,0,0]), np.array([[.9,.1,0,0,0,0],[0,.9,.1,0,0,0],[0,0,.9,.1,0,0],[0,0,0,.9,.1,0],[0,0,0,0,.9,.1],[0,0,0,0,0,1]]))\n","see_HMM = MyHMM(phones2indices(['sil', 's', 'iy', 'sil']), np.array([0.5, 0.5, 0, 0]), np.array([[.9,.1,0,0],[0,.9,.1,0],[0,0,.9,.1],[0,0,0,1]]))\n","she_HMM = MyHMM(phones2indices(['sil', 'sh', 'iy', 'sil']), np.array([0.5, 0.5, 0, 0]), np.array([[.9,.1,0,0],[0,.9,.1,0],[0,0,.9,.1],[0,0,0,1]]))\n","\n","# TODO: write your code to use your HMMs below here (or in a new block)"],"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["[0, 43, 5, 0]\n","[0, 10, 5, 0]\n","[0, 4, 17, 9, 26, 0]\n","[0, 23, 30, 9, 37, 0]\n","[0, 1, 5, 0]\n","[0, 14, 5, 0]\n"]}]},{"cell_type":"code","metadata":{"id":"9VYJ3BgWCUeY"},"source":["# computing class likelihoods\n","def compute_likeli(filename):\n","    tar_tensor = load_audio_to_melspec_tensor(dir + filename)\n","    return compute_phone_likelihoods(model, tar_tensor)\n","\n","def compute_hmm(filename):\n","    res = []\n","    likelihood = compute_likeli(filename)\n","    res.append(fee_HMM.forward(likelihood))\n","    res.append(pea_HMM.forward(likelihood))\n","    res.append(rock_HMM.forward(likelihood))\n","    res.append(burt_HMM.forward(likelihood))\n","    res.append(see_HMM.forward(likelihood))\n","    res.append(she_HMM.forward(likelihood))\n","    res.append(np.argmax(res))\n","    return res"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"czUNFYEVntTB"},"source":["result_table = []\n","result_table.append(compute_hmm('fee.wav'))\n","result_table.append(compute_hmm('pea.wav'))\n","result_table.append(compute_hmm('rock.wav'))\n","result_table.append(compute_hmm('burt.wav'))\n","result_table.append(compute_hmm('see.wav'))\n","result_table.append(compute_hmm('she.wav'))\n","result_table = np.array(result_table)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"OX36cpxrhruu","executionInfo":{"status":"ok","timestamp":1633642926773,"user_tz":300,"elapsed":168,"user":{"displayName":"Ting-Yu Dai","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17719512292427902131"}},"outputId":"aa98934d-a90a-4d91-8d51-da41a9ca8d72"},"source":["import pandas as pd\n","wav_lists = ['fee','pea','rock','burt','see','she']\n","hmm_lists = ['fee Hmm','pea Hmm','rock Hmm','burt Hmm','see Hmm','she Hmm']\n","pd.DataFrame(data = result_table[:,:6], index = wav_lists, columns= hmm_lists)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fee Hmm</th>\n","      <th>pea Hmm</th>\n","      <th>rock Hmm</th>\n","      <th>burt Hmm</th>\n","      <th>see Hmm</th>\n","      <th>she Hmm</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>fee</th>\n","      <td>210.104073</td>\n","      <td>179.535837</td>\n","      <td>-92.358515</td>\n","      <td>-85.893900</td>\n","      <td>191.100943</td>\n","      <td>183.554444</td>\n","    </tr>\n","    <tr>\n","      <th>pea</th>\n","      <td>250.326733</td>\n","      <td>268.477376</td>\n","      <td>8.474222</td>\n","      <td>71.812346</td>\n","      <td>236.598016</td>\n","      <td>235.196966</td>\n","    </tr>\n","    <tr>\n","      <th>rock</th>\n","      <td>-62.373003</td>\n","      <td>-5.380460</td>\n","      <td>157.733017</td>\n","      <td>66.335971</td>\n","      <td>-61.493682</td>\n","      <td>-63.290686</td>\n","    </tr>\n","    <tr>\n","      <th>burt</th>\n","      <td>-62.166606</td>\n","      <td>-19.362778</td>\n","      <td>116.139844</td>\n","      <td>220.500684</td>\n","      <td>-74.806470</td>\n","      <td>-96.786347</td>\n","    </tr>\n","    <tr>\n","      <th>see</th>\n","      <td>73.563557</td>\n","      <td>75.717636</td>\n","      <td>-176.480611</td>\n","      <td>-158.521863</td>\n","      <td>230.052460</td>\n","      <td>125.818204</td>\n","    </tr>\n","    <tr>\n","      <th>she</th>\n","      <td>78.157833</td>\n","      <td>91.857022</td>\n","      <td>-211.203001</td>\n","      <td>-191.500293</td>\n","      <td>124.567268</td>\n","      <td>281.692859</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         fee Hmm     pea Hmm    rock Hmm    burt Hmm     see Hmm     she Hmm\n","fee   210.104073  179.535837  -92.358515  -85.893900  191.100943  183.554444\n","pea   250.326733  268.477376    8.474222   71.812346  236.598016  235.196966\n","rock  -62.373003   -5.380460  157.733017   66.335971  -61.493682  -63.290686\n","burt  -62.166606  -19.362778  116.139844  220.500684  -74.806470  -96.786347\n","see    73.563557   75.717636 -176.480611 -158.521863  230.052460  125.818204\n","she    78.157833   91.857022 -211.203001 -191.500293  124.567268  281.692859"]},"metadata":{},"execution_count":37}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"ldN9FNpulErf","executionInfo":{"status":"ok","timestamp":1633648951001,"user_tz":300,"elapsed":242,"user":{"displayName":"Ting-Yu Dai","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17719512292427902131"}},"outputId":"2406f8ce-95e5-48d6-92b0-0e8f8d1a1c5c"},"source":["#max word\n","# print(table[:,6:].flatten())\n","maxlist = result_table[:,6:].flatten().astype(int)\n","maxword = [wav_lists[i] for i in maxlist]\n","table2 = np.zeros((6,8),dtype=object)\n","table2[:,:6] = result_table[:,:6]\n","table2[:,6] = maxlist\n","table2[:,7] = maxword\n","pd.DataFrame(data = table2, index=wav_lists, columns=['fee Hmm','pea Hmm','rock Hmm','burt Hmm','see Hmm','she Hmm','mostPossibleIndex','mostPossibleWord'])"],"execution_count":60,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>fee Hmm</th>\n","      <th>pea Hmm</th>\n","      <th>rock Hmm</th>\n","      <th>burt Hmm</th>\n","      <th>see Hmm</th>\n","      <th>she Hmm</th>\n","      <th>mostPossibleIndex</th>\n","      <th>mostPossibleWord</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>fee</th>\n","      <td>210.104</td>\n","      <td>179.536</td>\n","      <td>-92.3585</td>\n","      <td>-85.8939</td>\n","      <td>191.101</td>\n","      <td>183.554</td>\n","      <td>0</td>\n","      <td>fee</td>\n","    </tr>\n","    <tr>\n","      <th>pea</th>\n","      <td>250.327</td>\n","      <td>268.477</td>\n","      <td>8.47422</td>\n","      <td>71.8123</td>\n","      <td>236.598</td>\n","      <td>235.197</td>\n","      <td>1</td>\n","      <td>pea</td>\n","    </tr>\n","    <tr>\n","      <th>rock</th>\n","      <td>-62.373</td>\n","      <td>-5.38046</td>\n","      <td>157.733</td>\n","      <td>66.336</td>\n","      <td>-61.4937</td>\n","      <td>-63.2907</td>\n","      <td>2</td>\n","      <td>rock</td>\n","    </tr>\n","    <tr>\n","      <th>burt</th>\n","      <td>-62.1666</td>\n","      <td>-19.3628</td>\n","      <td>116.14</td>\n","      <td>220.501</td>\n","      <td>-74.8065</td>\n","      <td>-96.7863</td>\n","      <td>3</td>\n","      <td>burt</td>\n","    </tr>\n","    <tr>\n","      <th>see</th>\n","      <td>73.5636</td>\n","      <td>75.7176</td>\n","      <td>-176.481</td>\n","      <td>-158.522</td>\n","      <td>230.052</td>\n","      <td>125.818</td>\n","      <td>4</td>\n","      <td>see</td>\n","    </tr>\n","    <tr>\n","      <th>she</th>\n","      <td>78.1578</td>\n","      <td>91.857</td>\n","      <td>-211.203</td>\n","      <td>-191.5</td>\n","      <td>124.567</td>\n","      <td>281.693</td>\n","      <td>5</td>\n","      <td>she</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      fee Hmm  pea Hmm rock Hmm  ...  she Hmm mostPossibleIndex mostPossibleWord\n","fee   210.104  179.536 -92.3585  ...  183.554                 0              fee\n","pea   250.327  268.477  8.47422  ...  235.197                 1              pea\n","rock  -62.373 -5.38046  157.733  ... -63.2907                 2             rock\n","burt -62.1666 -19.3628   116.14  ... -96.7863                 3             burt\n","see   73.5636  75.7176 -176.481  ...  125.818                 4              see\n","she   78.1578   91.857 -211.203  ...  281.693                 5              she\n","\n","[6 rows x 8 columns]"]},"metadata":{},"execution_count":60}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wKS4KAg0lI1v","executionInfo":{"status":"ok","timestamp":1633646467936,"user_tz":300,"elapsed":147,"user":{"displayName":"Ting-Yu Dai","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17719512292427902131"}},"outputId":"4432ae36-989a-4ddd-d18f-1a4079d65093"},"source":["# Optimal state sequence\n","# Print the optimal hidden state sequence for the word “rock” using the HMM representing the word “rock”\n","\n","# paste it into your writeup.\n","rock_liki = compute_likeli('rock.wav')\n","rock_optimal_h = rock_HMM.viterbi(rock_liki)\n","print(rock_optimal_h)"],"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["(155.19284689253766, array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n","       1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3,\n","       3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5,\n","       5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5], dtype=int32))\n"]}]},{"cell_type":"code","metadata":{"id":"7hHeUym6yg84","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633648866656,"user_tz":300,"elapsed":99,"user":{"displayName":"Ting-Yu Dai","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17719512292427902131"}},"outputId":"5acb4323-ee7a-4527-b766-402cf823c821"},"source":["# Viterbi update\n","print('The original A matrix:')\n","print((np.exp(rock_HMM.A)).astype(np.float32))\n","print(f'The original likelihood: {rock_HMM.forward(rock_liki)}')\n","rock_HMM.viterbi_transition_update(rock_liki)\n","\n","\n","print('The updated A matrix:')\n","print((np.exp(rock_HMM.A)).astype(np.float32))\n","print(f'The updated likelihood: {rock_HMM.forward(rock_liki)}')"],"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["The original A matrix:\n","[[0.9 0.1 0.  0.  0.  0. ]\n"," [0.  0.9 0.1 0.  0.  0. ]\n"," [0.  0.  0.9 0.1 0.  0. ]\n"," [0.  0.  0.  0.9 0.1 0. ]\n"," [0.  0.  0.  0.  0.9 0.1]\n"," [0.  0.  0.  0.  0.  1. ]]\n","The original likelihood: 157.73301692893546\n","The updated A matrix:\n","[[0.9375     0.0625     0.         0.         0.         0.        ]\n"," [0.         0.9166667  0.08333334 0.         0.         0.        ]\n"," [0.         0.         0.9285714  0.07142857 0.         0.        ]\n"," [0.         0.         0.         0.90909094 0.09090909 0.        ]\n"," [0.         0.         0.         0.         0.8        0.2       ]\n"," [0.         0.         0.         0.         0.         1.        ]]\n","The updated likelihood: 158.19678594330463\n"]}]},{"cell_type":"code","metadata":{"id":"8gapEQodDcjI"},"source":[""],"execution_count":null,"outputs":[]}]}